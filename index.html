<html>
<head>
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>
    <title>Zhenbo Xu (ÂæêÊåØÂçö)</title>
    <meta content="Zhenbo Xu (ÂæêÊåØÂçö), detectrecog.github.io" name="keywords"/>
    <style media="screen" type="text/css">
        html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
            border: 0pt none;
            font-family: Arial, Helvetica, sans-serif;
            font-size: 100%;
            font-style: inherit;
            font-weight: inherit;
            margin: 0pt;
            outline-color: invert;
            outline-style: none;
            outline-width: 0pt;
            padding: 0pt;
            vertical-align: baseline;
        }

        a {
            color: #043d98;
            text-decoration: none;
        }

        a:focus, a:hover {
            color: #f09228;
            text-decoration: none;
        }


        * {
            margin: 0pt;
            padding: 0pt;
        }

        body {
            position: relative;
            margin: 2em auto 2em auto;
            width: 870px;
            font-family: Open Sans Light, Helvetica, sans-serif;
            font-size: 15px;
            background: #F4F6F6;
        }

        h2 {
            font-family: Lato, Verdana, Helvetica, sans-serif;
            font-size: 15pt;
            font-weight: 700;
        }

        h3 {
            font-family: Lato, Verdana, Helvetica, sans-serif;
            font-size: 16px;
            font-weight: 700;
        }

        strong {
            /* font-family: Lato, Verdana, Helvetica, sans-serif; */
            /* font-size: 13px; */
            font-weight: bold;
        }

        ul {
            /* list-style: circle; */
            list-style: disc;
        }

        img {
            border: none;
        }

        li {
            padding-bottom: 0.5em;
            margin-left: 1.4em;
        }

        alert {
            font-family: Arial, Helvetica, sans-serif;
            font-size: 14px;
            font-weight: bold;
            color: #FF0000;
        }

        em, i {
            font-style: italic;
        }

        div.section {
            clear: both;
            margin-bottom: 1.2em;
            background: #F4F6F6;
        }

        div.spanner {
            clear: both;
        }

        div.paper {
            clear: both;
            margin-top: 0.4em;
            margin-bottom: 0.7em;
            border: 2px solid #ddd;
            background: #fff;
            padding: 0.55em .8em 0.6em .8em;
            border-top-right-radius: 10px;
            border-top-left-radius: 10px;
            border-bottom-left-radius: 10px;
            border-bottom-right-radius: 10px;
            line-height: 140%;
        }

        div.paper2 {
            clear: both;
            margin-top: 0.4em;
            margin-bottom: 0.7em;
            border: 0px solid #ddd;
            background: #fff;
            padding: 0.55em .8em 0.6em .8em;
            border-top-right-radius: 10px;
            border-top-left-radius: 10px;
            border-bottom-left-radius: 10px;
            border-bottom-right-radius: 10px;
            line-height: 140%;
        }

        div.paper:hover {
            background: #FFFDEE;
            /* background-color: #242d36 ; */
        }

        div.paper2:hover {
            background: #FFFDEE;
            /* background-color: #242d36 ; */
        }

        div.bio {
            clear: both;
            margin-top: 0.4em;
            margin-bottom: 0.7em;
            border: 0px solid #ddd;
            background: #fff;
            padding: 0.55em .8em 0.6em .8em;
            border-top-right-radius: 10px;
            border-top-left-radius: 10px;
            border-bottom-left-radius: 10px;
            border-bottom-right-radius: 10px;
            line-height: 135%;
        }

        div.res {
            clear: both;
            margin-top: 0.4em;
            margin-bottom: 0.4em;
            border: 0px solid #ddd;
            background: #fff;
            padding: 0.65em .8em 0.15em .8em;
            border-top-right-radius: 10px;
            border-top-left-radius: 10px;
            border-bottom-left-radius: 10px;
            border-bottom-right-radius: 10px;
            line-height: 130%;
        }

        div.award {
            clear: both;
            margin-top: 0.4em;
            margin-bottom: 0.4em;
            border: 0px solid #ddd;
            background: #fff;
            padding: 0.65em .8em 0.15em .8em;
            border-top-right-radius: 10px;
            border-top-left-radius: 10px;
            border-bottom-left-radius: 10px;
            border-bottom-right-radius: 10px;
            line-height: 130%;
        }

        div.paper div {
            padding-left: 270px;
        }

        img.paper {
            /* margin-bottom: 0.4em; */
            float: left;
            width: 250px;

        }

        span.blurb {
            font-style: italic;
            display: block;
            margin-top: 0.75em;
            margin-bottom: 0.5em;
        }

        pre, code {
            font-family: Open Sans Light, Helvetica, sans-serif;
            font-size: 14px;
            margin: 1em 0;
            padding: 0;
        }

        .bot {
            font-size: 14%;
        }

        .ptypej {
            display: inline;
            padding: .0em .2em .05em;
            font-size: 85%;
            font-weight: bold;
            line-height: 1;
            background-color: #5cb85c;
            color: #FFFFFF;
            text-align: center;
            white-space: nowrap;
            vertical-align: baseline;
            margin-right: 6px;
        }

        .ptypec {
            display: inline;
            padding: .0em .2em .05em;
            font-size: 85%;
            font-weight: bold;
            line-height: 1;
            background-color: #428bca;
            color: #FFFFFF;
            text-align: center;
            white-space: nowrap;
            vertical-align: baseline;
            margin-right: 6px;
        }

        .ptypep {
            display: inline;
            padding: .0em .2em .05em;
            font-size: 85%;
            font-weight: bold;
            line-height: 1;
            background-color: #6B6B6B;
            color: #FFFFFF;
            text-align: center;
            white-space: nowrap;
            vertical-align: baseline;
            margin-right: 6px;
        }

        /* navigation */
        #nav {
            /* font-family: 'Lucida Grande', 'Lucida Sans Unicode', 'Lucida Sans',*/
            /* Corbel, Arial, Helvetica, sans-serif; */
            font-family: Georgia, Helvetica, sans-serif;
            position: fixed;
            top: 50px;
            /* left: 860px; */
            margin-left: 860px; /*1060*/
            width: 92px;
            font-size: 15px;
        }

        #nav li2 {
            margin-bottom: 1px;
        }

        ol {
            list-style: none;
        }

        #nav a {
            display: block;
            padding: 6px 9px 7px;
            color: #fff;
            background-color: #455A64;
            text-decoration: none;
        }

        #nav a:hover {
            color: #ffde00;
            /* background-color: #242d36 ; */
        }
    </style>

    <!-- <script type="text/javascript" async="" src="./files/ga.js"></script>
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-7953909-1']);
      _gaq.push(['_trackPageview']);

      (function () {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script> -->

    <script type="text/javascript" src="./files/hidebib.js"></script>

    <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet"
          type="text/css"/>
    <!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>-->
    <!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>-->
    <!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
</head>
<script>
    (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');


</script>
<script>
    (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function () {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
            m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-66888300-1', 'auto');
    ga('send', 'pageview');

</script>

<!-- <script src="./files/main.js"></script> -->

<body>
<ol id="nav">
    <li><a href="#home" title="Home">Home</a></li>
    <li><a href="#news" title="News">News</a></li>
    <li><a href="#pub" title="Papers">Papers</a></li>
    <li><a href="mailto:xuzhenbo@mail.ustc.edu.cn" title="Contact">Contact</a></li>
</ol>
<a name="home"></a>
<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 140px;">
    <div style="margin: 0px auto; width: 100%;">
        <img title="Zhenbo Xu (ÂæêÊåØÂçö)" style="float: left; padding-left: .01em; height: 140px;" src="me.jpg"/>
        <div style="padding-left: 10em; vertical-align: top; height: 120px;"><span
                style="line-height: 150%; font-size: 20pt;">Zhenbo Xu (ÂæêÊåØÂçö)</span><br/>
            <span><strong>Computer Vision Engineer</strong></span><br/>
            <span>Hangzhou Innovation Institute, Beihang University </span> <br/>
            <!--<span>Hangzhou Innovation Institute, Beihang University</span><br />-->
            <!-- <span><strong>Email  </strong>: wuwenhao17[at]mails[dot]ucas[dot]edu[dot]cn</span> <br />  -->
        </div>
    </div>
</div>
<!--<div style="clear: both; background-color: #fff; margin-top: 1.5em; padding: .2em; padding-left: .3em;">-->

<div style="clear: both;">
    <div class="section">
        <!-- <h2>(<a href='https://scholar.google.com/citations?user=kWADCMUAAAAJ&hl=zh-CN'>Google scholar</a>)</h2> -->
        <h2>About Me </h2>
        <div class="bio">
            Currently, I am a computer vision engineer in <a href="https://hzii.buaa.edu.cn/index.htm/">Hangzhou
            Innovation Institute, Beihang University</a>.
            In 2021, I received my Ph.D. in Computer Science from the University of Science and Technology of China.
            My research centers around Food calculation, MOTS and 3D Object Detection. I‚Äôm interested in weakly
            supervised learning and self-supervised learning.
            I've published articles in top-tier journals and conferences, including TPAMI,ICCV,CVPR,AAAI,ECCV.
            During my Ph.D. period, I served as a reviewer for TIP/ECCV and other journals/conferences.
            I also had a great time researching computer vision at <a href="http://research.baidu.com/Index/">Department
            of Computer Vision Technology (VIS), Baidu Inc. </a>
        </div>
    </div>


    <a name="news"></a>
    <div style="clear: both;">
        <div class="section">
            <h2>News</h2>
            <div class="paper">
                <ul>
                    <li> 2021.12: One paper accepted by <font color="DarkRed">AAAI2022</font>. üòä</li>
                    <li> 2021.07: One paper accepted by <font color="DarkRed">ICCV2021</font>. üòä</li>
                    <li> 2021.06: Graduated with a Ph.D. in Computer Science from the University of Science and
                        Technology of China. üéì
                    </li>
                    <li> 2021.06: One paper accepted by <font color="DarkRed">TPAMI2021</font>.</li>
                    <li> 2020.07: One paper was accepted for <b>Oral presentation</b> on <font
                            color="DarkRed">ECCV2020</font>.
                    </li>
                    <li> 2020.06: We <font color="Red">rank first</font> in the Track 2 of the <a
                            href="https://motchallenge.net/workshops/bmtt2020/index.html/">CVPR MOTChallenge 2020</a>.
                    </li>
                    <li> 2019.12: One paper was accepted for <b>Oral presentation</b> on <font
                            color="DarkRed">AAAI2020</font>.
                    </li>
                    <li> 2018.07: One paper accepted by <font color="DarkRed">ECCV2018</font>.</li>
                    <li> 2018.07: One paper was accepted for <b>Oral presentation</b> on <font
                            color="DarkRed">SECON2018</font>.
                    </li>
                    <li> 2016.06: Graduated with a B.S. in Computer Science from the University of Science and
                        Technology of China.
                    </li>

                </ul>
            </div>
        </div>
    </div>

    <div style="clear: both;">
        <div class="section">
            <h2 id="confpapers">Industrial Experience</h2>
            <div class="paper">
                <ul>
                    <li>
                        Mar. 2019 - May. 2020, Research Intern, <font color="Brown">Baidu Research</font> & <font
                            color="Brown">Baidu VIS</font>, hosted by <a
                            href=" ">Wei Zhang</a> and <a
                            href=" ">Xiao Tan</a>
                    </li>


                </ul>

                <div class="spanner"></div>
            </div>
        </div>
    </div>


    <a name="pub"></a>
    <div style="clear: both;">
        <div class="section">
            <h2 id="confpapers">Publications</h2>

            <!-- under review -->
            <div class="paper" id="xxx"><img class="paper" src="papers/Tpami/TPAMI.png"/>
                <div>
                    <a><b>PointTrackV2 for Efficient and Effective Online Multi-Object Tracking and Segmentation</b></a><br/>
                    <u><b style="color:darkred">Zhenbo Xu</b></u>, Wei Yang, ... <br/>
                    <i>Transactions on Pattern Analysis and Machine Intelligence <b><font color="DarkRed">(TPAMI)</font></b>,
                        2021 </i><br/>
                    [ <a href=''>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!-- <alert>An effective self-supervised video representation learning framework.</alert> -->
                </div>
                <div class="spanner"></div>
            </div>

            <!-- under review -->
            <div class="paper" id="xxx"><img class="paper" src="papers/ICCV2021/ICCV202.png"/>
                <div>
                    <a><b>Continuous Copy-Paste for One-stage Multi-object Tracking and Segmentation</b></a><br/>
                    <u><b style="color:darkred">Zhenbo Xu</b></u>, Wei Yang, ... <br/>
                    <i>International Conference on Computer Vision <b><font color="DarkRed">(ICCV)</font></b>, 2021 </i><br/>
                    [ <a href=''>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!-- <alert>An effective self-supervised video representation learning framework.</alert> -->
                </div>
                <div class="spanner"></div>
            </div>

            <!-- under review -->
            <div class="paper" id="xxx"><img class="paper" src="papers/ZoomNet/zoomnet_PASnet0829.jpg"/>
                <div>
                    <a><b>ZoomNet: Part-Aware Adaptive Zooming Neural Network for 3D Object Detection</b></a><br/>
                    <u><b style="color:darkred">Zhenbo Xu</b></u>, Wei Zhang, Xiaoqing Ye, Xiao Tan, Wei Yang, Shilei Wen, Errui Ding, Ajin Meng, Liusheng Huang <br/>
                    <i>Thirty-Fourth AAAI Conference on Artificial Intelligence <b><font color="DarkRed">(AAAI ORAL, top
                        5%)</font></b>, 2020 </i><br/>
                    [ <a href='https://www.aaai.org/Papers/AAAI/2020GB/AAAI-XuZ.558.pdf'>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!-- <alert>An effective self-supervised video representation learning framework.</alert> -->
                </div>
                <div class="spanner"></div>
            </div>

            <!-- under review -->
            <div class="paper" id="xxx"><img class="paper" src="papers/PointTrack/PointTrack.png"/>
                <div>
                    <a><b>Segment as Points for Efficient Online Multi-Object Tracking and Segmentation</b></a><br/>
                    <u><b style="color:darkred">Zhenbo Xu</b></u>, Wei Zhang, Xiao Tan, Wei Yang, Huan Huang, Shilei Wen, Errui Ding, Liusheng Huang <br/>
                    <i> European Conference on Computer Vision <b> <font color="DarkRed">(ECCV ORAL)</font></b>,
                        2020</i> <br/>
                    [ <a href='https://arxiv.org/abs/2007.01550'>PDF</a> ]
                    [ <a href='https://github.com/detectRecog/PointTrack'>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>

            <!-- under review -->
            <div class="paper" id="xxx"><img class="paper" src="papers/CCPD/CCPD.png"/>
                <div>
                    <a><b>Towards End-to-End License Plate Detection and Recognition: A Large Dataset and
                        Baseline</b></a><br/>
                    <u><b style="color:darkred">Zhenbo Xu</b></u>, Wei Yang, Ajin Meng, Nanxue Lu, Huan Huang, Changchun Ying, Liusheng Huang <br/>
                    <i> European Conference on Computer Vision <b> <font color="DarkRed">(ECCV)</font></b>, 2018</i>
                    <br/>
                    [ <a
                        href='http://openaccess.thecvf.com/content_ECCV_2018/papers/Zhenbo_Xu_Towards_End-to-End_License_ECCV_2018_paper.pdf'>PDF</a>
                    ]
                    [ <a href=''>Code</a> ] <br/>
                    <!-- <alert>An effective self-supervised video representation learning framework.</alert> -->
                </div>
                <div class="spanner"></div>
            </div>


            <!-- under review -->
            <div class="paper" id="xxx"><img class="paper" src="papers/PointTrack++/PointTrack++.png"/>
                <div>
                    <a><b>PointTrack++ for Effective Online Multi-Object Tracking and Segmentation</b></a><br/>
                    <u><b style="color:darkred">Zhenbo Xu</b></u>, Wei Zhang, Xiao Tan, Wei Yang, Xiangbo Su, Yuchen Yuan, Hongwu Zhang, Shilei Wen, Errui Ding, Liusheng Huang <br/>
                    <i> IEEE/CVF Conference on Computer Vision and Pattern Recognition <b> <font color="DarkRed">(CVPR
                        MOTChallenge ORAL)</font></b>, 2020</i> <br/>
                    [ <a href='https://motchallenge.net/workshops/bmtt2020/papers/PointTrack++.pdf'>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>

            <!-- under review -->
            <div class="paper" id="xxx"><img class="paper" src="papers/SECON/SECON.png"/>
                <div>
                    <a><b>Link Us If You Can: Enabling Unlinkable Communication on the Internet</b></a><br/>
                    <u><b style="color:darkred">Zhenbo Xu</b></u>, Wei Zhang, Yang Xu, Ajin Meng, Jianhua Liu, Qijian He, Liusheng Huang <br/>
                    <i> IEEE International Conference on Sensing, Communication and Networking <b> <font
                            color="DarkRed">(SECON ORAL)</font></b>, 2018</i> <br/>
                    [ <a href='https://ieeexplore.ieee.org/document/8397144'>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>

            <!-- Co-author -->
            <div class="paper" id="xxx"><img class="paper" src="papers/ACMMM2021/DSANet.png"/>
                <div>
                    <a><b>Revealing the Reciprocal Relations between Self-Supervised Stereo and Monocular Depth
                        Estimation</b></a><br/>
                    Zhi Chen, Wei Yang, <u><b style="color:darkred">Zhenbo Xu</b></u>, ... <br/>
                    <i> International Conference on Computer Vision <b> <font color="DarkRed">(ICCV)</font></b>,
                        2021</i> <br/>
                    [ <a href=''>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>

            <div class="paper" id="xxx"><img class="paper" src="papers/ACMMM2021/DSANet.png"/>
                <div>
                    <a><b>Associate-3Ddet: Perceptual-to-Conceptual Association for 3D Point Cloud Object Detection</b></a><br/>
                    Liang Du, Xiaoqing Ye, Xiao Tan, Jianfeng Feng, <u><b style="color:darkred">Zhenbo Xu</b></u>, Errui Ding, Shilei Wen<br/>
                    <i> International Conference on Computer Vision <b> <font color="DarkRed">(ICCV)</font></b>,
                        2020</i> <br/>
                    [ <a
                        href='http://openaccess.thecvf.com/content_CVPR_2020/html/Du_Associate-3Ddet_Perceptual-to-Conceptual_Association_for_3D_Point_Cloud_Object_Detection_CVPR_2020_paper.html'>PDF</a>
                    ]
                    [ <a href=''>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>


            <div class="paper" id="xxx"><img class="paper" src="papers/ACMMM2021/DSANet.png"/>
                <div>
                    <a><b>DCNet: Dense Correspondence Neural Network for 6DoF Object Pose Estimation in Occluded
                        Scenes</b></a><br/>
                    Zhi Chen, Wei Yang, <u><b style="color:darkred">Zhenbo Xu</b></u>, ... <br/>
                    <i> ACM International Conference on Multimedia <b> <font color="DarkRed">(ACMMM)</font></b>,
                        2020</i> <br/>
                    [ <a href='https://dl.acm.org/doi/abs/10.1145/3394171.3413672'>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>


            <div class="paper" id="xxx"><img class="paper" src="papers/ACMMM2021/DSANet.png"/>
                <div>
                    <a><b>POINTER NETWORKS FOR ARBITRARY-SHAPED TEXT SPOTTING</b></a><br/>
                    Yi Zhang, Wei Yang, <u><b style="color:darkred">Zhenbo Xu</b></u>, ... <br/>
                    <i> IEEE International Conference on Acoustics, Speech and Signal Processing <b> <font
                            color="DarkRed">(ICASSP)</font></b>, 2021</i> <br/>
                    [ <a href=''>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>

            <div class="paper" id="xxx"><img class="paper" src="papers/ACMMM2021/DSANet.png"/>
                <div>
                    <a><b>MASK4D: 4D CONVOLUTION NETWORK FOR LIGHT FIELD OCCLUSION REMOVAL</b></a><br/>
                    Yingjie Li, Wei Yang, <u><b style="color:darkred">Zhenbo Xu</b></u>, ... <br/>
                    <i> IEEE International Conference on Acoustics, Speech and Signal Processing <b> <font
                            color="DarkRed">(ICASSP)</font></b>, 2021</i> <br/>
                    [ <a href=''>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>

            <div class="paper" id="xxx"><img class="paper" src="papers/ACMMM2021/DSANet.png"/>
                <div>
                    <a><b>ADVERSARIAL ATTACKS ON OBJECT DETECTORS WITH LIMITED PERTURBATIONS</b></a><br/>
                    Zhenbo Shi, Wei Yang, <u><b style="color:darkred">Zhenbo Xu</b></u>, ... <br/>
                    <i> IEEE International Conference on Acoustics, Speech and Signal Processing <b> <font
                            color="DarkRed">(ICASSP)</font></b>, 2021</i> <br/>
                    [ <a href=''>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>

            <div class="paper" id="xxx"><img class="paper" src="papers/ACMMM2021/DSANet.png"/>
                <div>
                    <a><b>VK-NET: CATEGORY-LEVEL POINT CLOUD REGISTRATION WITH UNSUPERVISED ROTATION INVARIANT
                        KEYPOINTS</b></a><br/>
                    Zhi Chen, Wei Yang, <u><b style="color:darkred">Zhenbo Xu</b></u>, ... <br/>
                    <i> IEEE International Conference on Acoustics, Speech and Signal Processing <b> <font
                            color="DarkRed">(ICASSP)</font></b>, 2021</i> <br/>
                    [ <a href=''>PDF</a> ]
                    [ <a href=''>Code</a> ] <br/>
                    <!--    <alert>An efficient plug-and-play module for effective video-level representation learning.</alert>-->
                </div>
                <div class="spanner"></div>
            </div>


            <div style="clear: both;">
                <div class="section">
                    <h2 id="confpapers">Contests</h2>
                    <div class="paper">
                        <ul>
                            <!-- <li>The NTIRE Perceptual Extreme Super-Resolution Challenge on CVPR'20: Won 1st in SSIM, 2nd in PSNR, and 11th in LPIPS.</li> -->
                            <li><a href="https://motchallenge.net/workshops/bmtt2020/index.html/">CVPR MOTChallenge
                                2020</a>: 1st place in Track 2.
                            </li>

                        </ul>
                        <div class="spanner"></div>
                    </div>
                </div>
            </div>


            <div style="clear: both;">
                <div class="section"><h2>Awards</h2>
                    <div class="paper">
                        <li>Excellent Graduates of University of Science and Technology of China, 2021</li>
                        <li>Excellent Graduates of Anhui Province, China, 2021</li>
                        <li>National Scholarship, 2020</li>
                        <li>Honorary Certificate of Graduate Academic Forum of School of Computer Science, University of
                            Science and Technology of China, 2020
                        </li>
                        <li>The Most Outstanding Intern in Baidu (only 2 recipient in the Department), 2019</li>
                        <li>YuanQian Scholarship, 2019</li>
                        <li>DuShuHu, Suzhou Scholarship, 2018</li>

                    </div>
                </div>
            </div>


            <div style="clear: both;">
                <div class="section"><h2>Academic Activities</h2>
                    <div class="paper"><h3>Presentation</h3> <br>
                        <li> AAAI 2020 Oral presentation</li>
                        <li> ECCV 2020 Oral presentation</li>
                        <li> CVPRW 2020 Oral presentation</li>
                        <li> SECON 2018 Oral presentation</li>


                        <h3>Reviewer</h3> <br>
                        <li> European Conference on Computer Vision (ECCV)</li>
                        <li> IEEE Transactions on Image Processing (TIP)</li>
                    </div>
                </div>
            </div>


            <div style="clear: both;">
                <div class="section"><h2>Girl Friend</h2>
                    <div class="paper">
                        Ajin Meng ‚ù§Ô∏è

                    </div>
                </div>
            </div>


            <div style="clear:both;">
                <p align="right"><font size="5">Last Updated on 5 Aug, 2021</a></font></p>
                <p align="right"><font size="5">Published with <a href='https://pages.github.com/'>GitHub
                    Pages</a></font></p>
            </div>

            <hr>
            <div id="clustrmaps-widget"></div>
            <script type='text/javascript' id='clustrmaps'
                    src='//cdn.clustrmaps.com/map_v2.js?cl=0e1633&w=300&t=tt&d=N0ZXDEaZVrn2LXkG_byNAa2NLm2v6WRQIUifhg-2f1A&co=0b4975&ct=cdd4d9&cmo=3acc3a&cmn=ff5353'></script>
            <!-- 	<script type="text/javascript" id="clstr_globe" src="//cdn.clustrmaps.com/globe.js?d=N0ZXDEaZVrn2LXkG_byNAa2NLm2v6WRQIUifhg-2f1A"></script> -->

</body>
</html>
